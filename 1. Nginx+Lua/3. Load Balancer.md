# Load Balancer

官方文档移步：https://docs.nginx.com/nginx/admin-guide/load-balancer/

## Http Load Balancing

负载均衡是使多应用间优化资源利用、扩大吞吐量、减少延迟和确保容错配置的一种通用技术。

### 基本使用

使用 `upstream` 指令命令负载均衡服务器组名称，在虚拟主机中代理需要使用对应名称，本例 *backend*。

本例上游服务器组有两台相同配置的服务器和一台备份服务器，只有其它服务器不可用的情况下备份服务器才提供服务。由于没有指定负载均衡算法，默认使用 `轮询`。

转发请求使用  `proxy_pass` 指令（或者相应的协议使用 `fastcgi_pass`、`memcached_pass`、`scgi_pass`、`uwsgi_pass` 指令）。

```nginx
http {
    # 负载均衡上游服务器组
    upstream backend {
        server backend1.example.com;
        server backend2.example.com;
        server 192.0.0.1 backup;
    }
    
    server {
        location / {
            # 转发至 backend 组名的负载均衡
            proxy_pass http://backend;
        }
    }
}
```

### 负载均衡算法

开源版支持四种方法而 *Plus* 额外支持另外两种：

- Round Robin

  轮询，请求平均地分发到上游服务器，并且参考 `weight` 权值。

  不需要额外命令设置，默认开启。

- Least Connections

  最少连接数，请求分发到活跃连接数最少服务器，并且参考 `weight`。

  使用 `least_conn` 命令。

  ```nginx
  upstream backend {
      least_conn;
      server backend1.example.com;
      server backend2.example.com;
  }
  ```

- IP Hash

  IP 哈希，使同一个客户端 IP 访问同一个上游服务器。通过 *IPv4* 前3个字节或整个 *IPv6* 计算哈希值。

  使用 `ip_hash` 命令。

  ```nginx
  upstream backend {
  	ip_hash;
  	# server group
  }
  ```

  如果有上游服务器需要临时移除，可以标记为 `down` 这样可以维持当前客户端 IP 地址的哈希值；原本分发到移除服务器上请求将会自动分发到上游服务器组的下一个服务器。

  ```nginx
  upstream backend {
      ip_hash;
      server backend1.example.com;
      server backend2.example.com;
      server backend3.example.com down;
  }
  ```

- Generic hash

  通用哈希，用户可以指定字符串、变量或者两者的结合来计算哈希值。

  使用 `hash` 命令。

  ```nginx
  upstream backend {
      hash $request_uri consistent;
      server backend1.example.com;
      server backend2.example.com;
  }
  ```

  可选参数 `consistent` 能够使哈希映射保持不变，这样上游服务器增加或者减少只会导致少量的重新映射。

- Least Time(NGINX Plus only)

  最少时间，负载均衡选择平均延迟最小以及活跃连接数最少的。平均延迟通过指定 `header`、`last_byte`、`last_byte inflight` 计算得出。

  使用 `least_time` 命令。

  ```nginx
  upstream backend {
      least_time header;
      server backend1.example.com;
      server backend2.example.com;
  }
  ```

- Random

  随机，请求随机地分发到上游服务器。

  如果指定了 `two` 参数，那么

  1. NGINX 通过权值随机选择两台服务器；
  2. 通过指定的方法在两台中选择一台：
     - `least_conn`
     - `least_time=header` (NGINX Plus)
     - `least_time=last_byte` (NGINX Plus)

  使用 `random` 命令。

  ```nginx
  upstream backend {
      least_time header;
      server backend1.example.com;
      server backend2.example.com;
      server backend3.example.com;
      server backend4.example.com;
  }
  ```

  该方法适合分布式环境，例如多个负载均衡分发到同一组上游服务器；单台负载均衡适合其它方法。

  **注意：**如果要指定算法，应该将相应命令置于 `upstream` 块 `server` 命令之上。

### 权重

在轮询算法下每台上游服务器默认权重为 `1`。

```nginx
upstream backend {
    server backend1.example.com weight=5;
    server backend2.example.com;
}
```

本例中，每六个请求中五个发往第一台上游服务器，一个发往第二台服务器。

### 慢启动

慢启动能够防止服务器刚恢复就过载。

NGINX Plux 提供 *慢启动* 能够使上游服务器的权重从零慢慢提高到设定值。通过在 `server` 指令中引入 `slow_start` 参数。

```nginx
upstream backend {
    server backend1.example.com slow_start=30s;
    server backend2.example.com;
}
```

本例 `slow_start=30s` 设置服务器在三十秒内提升连接数至正常值。

如果上游服务器组只有单台，那么 `max_fails`、`fail_timeout`、`slow_start` 参数会被忽略并且该服务器被认作一直可用的。

### 持久化会话

NGINX Plus 可以使同一个用户会话分发到同一台上游服务器。

NGINX Plus 支持三种方法，使用 `sticky` 指令配置。开源版使用上方提到的 `hash` 或 `ip_hash` 命令。

- Sticky cookie

  NGINX Plux 将第一次分发请求的上游服务器标识放如会话 *cookie* 中，以后的请求都会按照 *cookie* 中的值发送到第一次分发的上游服务器。

  ```nginx
  upstream backend {
      server backend1.example.com;
      server backend2.example.com;
      sticky cookie sev_id expires=1h domain=.example.com path=/;
  }
  ```

  本例使用 `sev_id` 参数设置 *cookie* 名称。可选 `expires`  参数指定浏览器保留 *cookie* 时间；可选 `domain` 参数指定使用的域名以及可选 `path` 参数指定 *cookie* 的可用路径。

  本方法使最简单的持久化会话的方法。

- sticky route

  NGINX Plus 收到第一条请求时向客户端声明一个 "route"。随后的请求对比 `server` 命令的 `route` 参数分发到指定的上游服务器。路由信息通过 *cookie* 或者请求请求的 *URI*。

  ```nginx
  upstream backend {
      server backend1.example.com route=a;
      server backend2.example.com route=b;
      sticky route $route_cookie $route_uri;
  }
  ```

- Cookie lean

  NGINX Plux 首先通过检查请求或响应找到会话标识符。NGINX Plux ”学习“哪台上游服务器对应哪种会话标识符。通常，标识符在 *HTTP cookie* 中。当一个请求的会话标识符负载均衡”学会了“，负载均衡将其分发到相应的服务器上：

  ```nginx
  upstream backend {
      server backend1.example.com;
      server backend2.example.com;
      sticky learn
          create=$upstream_cookie_examplecookie
          lookup=$cookie_examplecookie
          zone=cline_session:1m
          timeout=1h;
  }
  ```

  本例有一台上游服务器通过设置 *cookie* `EXAMPLECOOKIE` 开启了新会话。参数解释见官方文档。

  本方法不用维持客户端的之间的 *cookie*，所有的信息都保存与共享的内存区域。

  如果负载均衡集群使用该方法，可以同步它们共享的内存区域。

### 限制连接数 

 NGINX Plus 可以通过 `max_conns` 参数设置上游服务器的最大连接数。

当到达最大连接数，请求会被放置于队列中，可以通过 `queue` 命令设置同时能置于队列中的最大请求数。

```nginx
upstream backend {
    server backend1.example.com max_conns=3;
    server backend2.example.com;
    queue 100 timeout=70;
}
```

客户端会收到错误返回如果队列满了或者无法指定上游服务器。

如果在其它 *worker processes* 中开着闲置的长连接，`max_conns`  限制会被忽略。实际服务器的连接数会超过多个 *worker processes* 共享的配置文件中设置的 `max_conns` 数。

### 配置健康检测

NGINX 可以持续监测上游服务器，避免挂了的服务器以及优雅地将恢复地服务器加入负载均衡服务器组中。

### Worker Processes 间数据共享

可以设置 `zone` 命令来设置工作进程间地数据共享，否则每个进程维护自己的计数器，例如负载均衡中最小连接数算法，在（低负荷时明显）大家都根据自己的计数器去选择上游服务器；又如 `max_fails`，其中一个进程失败了，别的进程不知道最终导致所有进程都标记为失败的数量为 `max_fails` 乘以进程数。

```nginx
upstream backend {
    zone backend 32k;
    least_conn;
    server backend1.example.com;
    server backend2.example.com;
}
```

### 通过 DNS 配置负载均衡

如果上游服务器使用域名指定，NGINX Plus 能够监视到域名的 *IP* 改动，并不需要重启，动态更新上游服务器组。

通过在 `http` 块包含 `resolve` 和 `server` 命令。

```nginx
http {
    resolver 10.0.0.1 valid=300s ipv6=off;
    resolver_timeout 10s;
    server {
        location / {
            proxy_pass http://backend;
        }
    }
    upstream backend {
        # ...
        server backend1.example.com resolve;
    	server backend2.example.com resolve;
    }
}
```

本例，`server` 命令的 `resolve` 参数使 NGINX Plux 周期性地解析域名。

`resolver` 制定了 DNS 服务器 *10.0.0.1* 来解析上游服务器组域名。默认使用域名地 *TTL* 间隔重新获取解析，但也能指定 `valid` 参数设置间隔时间。默认 *IPv4* 和 *IPv6* 都能支持解析，本例禁用了 *IPv6* 只是用 *IPv4* 地址负载均衡。

如果一个域名能够解析多个地址，地址会保存与上游配置和负载均衡中。

### Microsoft Exchange server 地负载均衡

NGINX Plus R7 及之后，NGINX Plus 能够代理 Microsoft Exchange 流量至单台或负载均衡服务器组。

完成案例：

```nginx
http {
    # ...
    upstream exchange {
        zone exchange 64;
        ntlm;
        server exchange1.example.com;
        server exchange2.example.com;
    }
    
    server {
        listen 443 ssl;
        # ssl certificate settings
        # ...
        location / {
            proxy_pass https://exchange;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
        }
    }
}
```

### 通过 NGINX Plus API 动态配置

NGINX Plux 提供接口可以查看服务器、修改配置、增加或移除服务器。

## TCP and UDP Load Balancing

NGINX Plus Release 5 及之后，NGINX Plux 能够代理或负载均衡 *TCP* 流量。

NGINX Plux Release 9 及之后，NGINX Plux 能够代理或负载均衡 *UDP* 流量。

开源版 NGINX 需要带上 `--with-stream` 编译安装。

### 配置反向代理

1. 创建顶级 `steam` 块：

   ```nginx
   stream {
       # ...
   }
   ```

2. 为每一个虚拟服务器在 `steam` 块中指定单个或多个 `server` 配置块。

3. 在每个 `server` 块中包含 `listen` 命令指定监听地 *IP* 和/或 端口号。

   *UDP* 流量同时需要包含 `udp` 参数。*TCP* 是默认协议无需指定相应参数：

   ```nginx
   stream {
       server {
           listen 12345;
           # ...
       }
       
       server {
           listen 53 udp;
           # ...
       }
   }
   ```

4. 包含 `proxy_pass` 指定指定代理服务器或上游服务器群：

   ```nginx
   stream {
       server {
           listen 12345;
           # TCP 转发至"stream_backend" 上游服务器组
           proxy_pass stream_backend;
       }
       
       server {
           listen 12346;
           # TCP 直接转发至指定服务器
           proxy_pass backend.example.com:12346;
       }
       
       server {
           listen 53 udp;
           # UDP 转发至 "dns_servers" 上游服务器组
           proxy_pass dns_servers;
       }
   }
   ```

5. 如果代理服务器有多个网络接口，可选地可以在连接上游服务器时指定源 *IP* 地址。当被代理地服务器被配置成接受指定地 *IP* 地址或地址组时非常有用。

   包含 `proxy_bind` 命令和合适地网络接口地址：

   ```nginx
   stream {
       # ...
       server {
           listen 127.0.0.1:12345;
           proxy_pass backend.example.com:12345;
           proxy_bind 127.0.0.1:12345;
       }
   }
   ```

6. 可选地，可以调优两个内存缓冲区的大小，NGINX 可以将来自客户端和上游连接的数据置于其中。如果数据量较小，可以减低缓冲区大小来节省内存开支；如果数据量较大，可以增大缓冲区来减少套接字读取操作的次数。一旦一个连接上接收到数据，NGINX 读取数据并传发到另一个连接上使用 `proxy_buffer_size` 命令调整缓冲区：

   ```nginx
   stream {
       # ...
       server {
       	listen 127.0.0.1:12345;
           proxy_pass backend.example.com:12345;
           proxy_buffer_size 16k;
       }
   }
   ```

### 配置 TCP 和 UDP 负载均衡

1. 在顶级 `stream` 块中创建一个或多个 `upstreams` 块：

   ```nginx
   stream {
       upstream stream_backend {
           # ...
       }
       
       upstream dns_servers {
           # ...
       }
   }
   ```

   需要确保与 `proxy_pass` 命令中所要负载的上游服务器组名字保持一致。

2. 构建上游服务器组，在 `upstream` 块中每个服务器通过 `server` 命令增加，需要 *IP* 地址或者域名以及必须指定端口。协议不许额外定义，在 `listen` 命令中已经设置.

   ```nginx
   stream {
       upstream stream_backend {
           server backend1.example.com:12345;
           server backend2.example.com:12345;
           server backend3.example.com:12345;
           # ...
       }
       
       upstream dns_servers {
           server 192.168.136.130:53;
           server 192.168.136.131:53;
           # ...
       }
   }
   ```

3. 配置上游服务器组的负载均衡方法，方法选项有：

   - Round Robin
   - Least Connections
   - Least Time(NGINX Plus only)
   - Hash
   - Random

   负载均衡方法与 *Http* 一致，不再复述。

4. 可选地，可以为每个上游服务器指定最大连接数、服务器权重等：

   ```nginx
   upstream stream_backend {
       hash $remote_addr consistent;
       server backend1.example.com:12345 weight=5;
       server backend2.example.com:12345;
       server backend3.example.com:12345 max_conns=3;
   }
   ```

   一个可选的方案是代理至一台服务器而不是上游服务器组。如果通过主机名指定服务器，NGINX会使用轮询算法向解析出多个 *IP* 地址进行分发。这种情形下，必须在 `proxy_pass` 命令中指定服务器端口并且不能在 *IP* 地址或主机名前指定协议（前缀）。

   ```nginx
   stream {
       # ...
       server {
           listen 12345;
           proxy_pass backend.example.com:12345;
       }
   }
   ```

### 配置健康检测

NGINX 可以持续监测 *TCP* 或 *UDP* 上游服务器，避免挂了的服务器以及优雅地将恢复地服务器加入负载均衡服务器组中。

### 运行中配置

上游服务器组能够简单地通过 NGINX Plux REST API 在运行时修改配置。通过这个接口，可以查看所有上游服务器或单个、修改服务器参数以及增减上游服务器。

使用运行中配置：

1. 创建顶级 `http` 块：

   ```nginx
   http {
       # ...
   }
   ```

2. 创建一个 `location` 来接受配置请求，例如 *api*：

   ```nginx
   http {
       server {
           locaion /api {
               # ...
           }
       }
   }
   ```

3. 在 `location`  块使用 `api` 命令：

   ```nginx
   http {
       server {
           locaion /api {
               api;
               # ...
           }
       }
   }
   ```

4. 默认，NGINX Plus API 只能只读数据。`write=on` 参数能够读写修改上游配置：

   ```nginx
   http {
       server {
           location /api {
               api write=on;
               # ...
           }
       }
   }
   ```

5. 配置 `allow` 和 `deny` 命令：

   ```nginx
   http {
       server {
           locaion /api {
               api write=on;
               allow 127.0.0.1;	# 允许本地访问
               deny all;
           }
       }
   }
   ```

6. 当 *API* 开启了写的模式时，推荐限制 `PATH` 、`POST`、`DELETE` 请求的权限。可以使用 *HTTP basic authentication*：

   ```nginx
   http {
       server {
           locaion /api {
               limit_except GET {
                   auth_basic "NGINX Plus API";
                   auth_basic_user_file /path/to/passed/file;
               }
               api write=on;
               allow 127.0.0.1;	# 允许本地访问
               deny all;
           }
       }
   }
   ```

7. 为上游服务器组创建一个共享的内存空间，这样所有的工作进程能够使用相同的配置信息。在顶级 `stream` 块中找到目标上游服务器组，增加 `zone` 命令并指定空间名和内存大小：

   ```nginx
   stream {
       upstream stream_backend {
           zone backend 64k;
           # ...
       }
   }
   ```

完整例子：

```nginx
stream {
    # ...
    upstream appservers {
        zone appservers 64k;
        server appserv1.example.com:12345 weight=5;
        server appserv2.example.com:12345 fail_timeout=5s;
        server backup1.example.com:12345 backup;
        server backup2.example.com:12345 backup;
    }
    
    server {
        proxy_pass appservers;
        health_check;
    }
}
http {
    # ...
    server {
        locaion /api {
            limit_except GET {
                auth_basic "NGINX Plus API";
                auth_basic_user_file /path/to/passed/file;
            }
            api write=on;
            allow 127.0.0.1;	# 允许本地访问
            deny all;
        }
    }
}
```

本例，`location` 只能本地地址访问。

可以使用任意方法向 NGINX 发送配置命令，例如 *curl*。

例如，发送一条 `POST` 请求向服务器组增加一台新的服务器：

```bash
curl -X POST -d '{ \
	"server": "appserv3.example.com:12345", \
	"weight": 4 \
}' -s 'http://127.0.0.1/api/5/stream/upstreams/appservers/servers'
```

发送一条 `DELETE` 请求从服务器组移除一台服务器：

```bash
curl -X DELETE -s 'http://127.0.0.1/api/5/stream/upstreams/appservers/servers/0'
```

发送一条 `PATCH` 请求更新一台服务器参数：

```bash
curl -X PATCH -d '{"down": true}' -s \
'http://127.0.0.1/api/5/http/upstreams/appservers/servers/0'
```

### TCP 与 UDP 负载均衡配置实例

```nginx
stream {
    upstream stream_backend {
        least_conn;
        server backend1.example.com:12345 weight=5;
        server backend2.example.com:12345 max_fails=2 fail_timeout=30s;
        server backend3.example.com:12345 max_conns=3;
    }
    
    upstream dns_servers {
        server 192.168.136.130:53;
        server 192.168.136.131:53;
        server 192.168.136.133:53;
    }
    
    server {
    	listen 12345;
        proxy_pass stream_backend;
        # 向一台服务器开始代理超时时间
        proxy_timeout 3s;
        # 与上游服务器建立连接超时时间
        proxy_connect_timeout 1s;
    }
    
    server {
    	listen 53 udp;
        proxy_pass dns_servers;
    }
    
    server {
        listen 12346;
        proxy_pass backend4.example.com:12346;
    }
}
```

## HTTP 健康检测

NGINX 可以持续监测上游服务器，避免挂了的服务器以及优雅地将恢复地服务器加入负载均衡服务器组中。

NGINX 开源版和 NGINX Plus 支持被动健康检测；

NGINX Plus 支持主动健康检测和状态检测板。

### 被动健康检测

系统监视事务，并尝试恢复连接失败的上游服务器。如果仍然失败，则标记为不可用并暂时停止向其分发请求直到其被标记为可用。

当服务器满足`server` 命令的以下参数时标记为不可用：

- `fail_timeout`

  该段时间内，达到失败尝试的次数时服务器被标记为不可用；也是服务器被标记为不可用的时长。

  默认为十秒。

- `max_fails`

  `fail_timeout` 失败尝试恢复达到的次数后服务器被标记为不可用。

  默认为一次。

本例，如果系统尝试发送一个请求，上游服务器在三十秒内尝试三次都没有收到响应后，该服务器被标记三十秒内不可用：

```nginx
upstream backend {
    server backend1.example.com;
    server backend2.example.com max_fails=3 fail_timeout=30s;
}
```

如果服务器组只有一台上游服务器，则 `fail_timeout` 和 `max_fails` 参数将会忽略，该服务器也永远不会被标记为不可用。

#### 慢启动

 略。

该功能 NGINX Plus 独有。

### 主动健康检测

NGINX Plus 周期性地向各个服务器发送健康检测请求，通过验证响应主动健康检测。

开启主动健康检测：

1. 在代理处增加 `health_check` 命令：

   ```nginx
   server {
       location / {
           proxy_pass http://backend;
           health_check;
       }
   }
   ```

   默认，每五秒 NGINX Plus 向上游服务器的 '/' 路径发送一个请求；如果通讯错误（状态码不在 `200` 和 `399` 之间）或者超时，系统在其再次通过健康检测之前都不会向其转发请求。

   可以通过 `port` 参数指定另一个端口来进行健康检测：

   ```nginx
   server {
       location / {
           proxy_pass http://backend;
           health_check port=8080;
       }
   }
   ```

2. 上游服务器组中设定共享内存空间：

   ```nginx
   http {
       upstream backend {
           zone backend 64k;
           # ...
       }
   }
   ```

   如此每个工作进程就可以使用相同的计数器来追踪服务器组的响应。

   可以修改 `health_check` 参数改变默认的检测策略：

   ```nginx
   location / {
       proxy_pass http://backend;
       health_check interval=10 fails=3 passes=2;
   }
   ```

   本例，`interval` 参数使两次检测的时差从五秒增加到了十秒；`fails` 参数代表失败三次后标记为不可用，默认一次；`passes` 参数标识两次连续成功响应检测后才能重新标记为可用，默认一次。

#### 指定请求 URI

使用 `uri` 参数可以指定检测的 *URI*：

```nginx
location / {
    proxy_pass http://backend;
    health_check uri=/some/path;
}
```

指定的 *URI* 会被追加到上游服务器组中服务器信息域名或 *IP* 地址后面。

#### 自定义条件

可以自定义健康检测响应需要满足的条件。条件写在 `match` 块，其名应与 `health_check` 命令中 `match` 参数一致：

1. 在 `http` 作用域内定义 `match` 块：

   ```nginx
   http {
       # ...
       match server_ok {
           # tests are here
       }
   }
   ```

2. `health_check` 命令后增加参数 `match` 且值与 `match` 块名一致：

   ```nginx
   http {
       # ...
       match server_ok {
           status 200-399;
           body !~ "maintenance mode";
       }
       server {
           # ...
           location / {
               proxy_pass http://backend;
               health_check match=server_ok;
           }
       }
   }
   ```

   本例条件为响应状态码在 `200` 至 `399` 之间且响应体中不包含字符串 *maintenance mode*。

`match` 指令使 NGINX Plus 可以检测响应的状态码、头部、响应体（正则表达式）。该指令可以包含一个状态码条件、一个响应体条件和多个头部条件。响应必须满足所有条件才能通过健康检测。

例如，响应的状态码为 `200`，头部 `Content-Type` 值为 `text/html` 并且响应体中包含 *Welcome to nginx!*：

```nginx
match welcome {
    status 200;
    header Content-Type = text/html;
    body ~ "Welcome to nginx!";
}
```

`!` 可以取反。本例，当状态码不是 `301`、`302`、`303` 和 `307` 并且头部不含 `Refresh` 时通过检测：

```nginx
match not_redirect {
    status ! 301-303 307;
    header ! Refresh;
}
```

健康检测同样也能运用于非 *HTTP* 协议如 `FastCGI`、`memcached`、`SCGI`、`uwsgi` 或者 `TCP` 和 `UDP`。

## TCP 健康检测

NGINX 可以持续监测 *TCP* 上游服务器，避免挂了的服务器以及优雅地将恢复地服务器加入负载均衡服务器组中。

### 被动 TCP 健康检测

略。

#### 慢启动

略。

### 主动 TCP 健康检测

如果 NGINX Plus 周期性的健康检测连接无法建立，那么服务器会标记为不可用。

开启主动健康检测：

1. 开启共享内存空间。

2. 使用 `health_check` 命令开启主动检测。

3. 必要时使用 `health_check_timeout`  命令减少两个检测之间的超时。该命令覆盖 `proxy_timeout` 的健康检测值。为了健康检测，超时应该设置的明显小一些。

   ```nginx
   stream {
       # ...
       server {
           listen 12345;
           proxy_pass stream_backend;
           health_check;
           health_check_timeout 5s;
       }
   }
   ```

4. 默认 NGINX Plus 使用 `server` 命令中的端口进行检测。可以通过 `port` 参数指定其它端口。

#### 微调 TCP 健康检测

默认 NGINX Plus 每五秒尝试向每个服务器建立连接，如失败则标记为不可用。

略。

#### "match {}" 配置块

可以自定义检测条件：

1. 在 `stream` 作用域内定义 `match` 块：

   ```nginx
   stream {
       # ...
       match tcp_test {
           # ...
       }
   }
   ```

2. `health_check` 命令后增加参数 `match` 且值与 `match` 块名一致。

3. 在 `match` 块中指定检测通过的条件。块中可以使用以下参数：

   - `send`

     要发送到服务器的文本字符串或十六进制文字(“/x”后跟两个十六进制数字)。

   - `expect`

     服务器返回的数据需要匹配的文字字符串或正则表达式。

   可以任意组合使用，但同时每个参数不能多余一个。

   - 如果两个参数都没有指定，将检测是否能建立连接。

   - 如果指定了 `expect` 参数，则期望服务器无条件地首先发送数据：

     ```nginx
     match pop3 {
         expect ~* "\+OK";
     }
     ```

   - 如果指定了 `send` 参数，能够建立连接并且指定的字符串会发送到服务器上：

     ```nginx
     match pop_quit {
         send QUIT;
     }
     ```

   - 如果两个参数都指定了，那么 `send` 参数发送后接收到的数据必须满足 `expect` 参数的正则表达式：

     ```nginx
     match http {
         send "GET / HTTP/1.0\r\nHost: localhost\r\n\r\n";
         expect ~* "200 OK";
     }
     ```

     

   