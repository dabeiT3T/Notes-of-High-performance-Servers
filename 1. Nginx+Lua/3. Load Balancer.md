# Load Balancer

官方文档移步：https://docs.nginx.com/nginx/admin-guide/load-balancer/

## Http Load Balancing

负载均衡是使多应用间优化资源利用、扩大吞吐量、减少延迟和确保容错配置的一种通用技术。

### 基本使用

使用 `upstream` 指令命令负载均衡服务器组名称，在虚拟主机中代理需要使用对应名称，本例 *backend*。

本例上游服务器组有两台相同配置的服务器和一台备份服务器，只有其它服务器不可用的情况下备份服务器才提供服务。由于没有指定负载均衡算法，默认使用 `轮询`。

转发请求使用  `proxy_pass` 指令（或者相应的协议使用 `fastcgi_pass`、`memcached_pass`、`scgi_pass`、`uwsgi_pass` 指令）。

```nginx
http {
    # 负载均衡上游服务器组
    upstream backend {
        server backend1.example.com;
        server backend2.example.com;
        server 192.0.0.1 backup;
    }
    
    server {
        location / {
            # 转发至 backend 组名的负载均衡
            proxy_pass http://backend;
        }
    }
}
```

### 负载均衡算法

开源版支持四种方法而 *Plus* 额外支持另外两种：

- Round Robin

  轮询，请求平均地分发到上游服务器，并且参考 `weight` 权值。

  不需要额外命令设置，默认开启。

- Least Connections

  最少连接数，请求分发到活跃连接数最少服务器，并且参考 `weight`。

  使用 `least_conn` 命令。

  ```nginx
  upstream backend {
      least_conn;
      server backend1.example.com;
      server backend2.example.com;
  }
  ```

- IP Hash

  IP 哈希，使同一个客户端 IP 访问同一个上游服务器。通过 *IPv4* 前3个字节或整个 *IPv6* 计算哈希值。

  使用 `ip_hash` 命令。

  ```nginx
  upstream backend {
  	ip_hash;
  	# server group
  }
  ```

  如果有上游服务器需要临时移除，可以标记为 `down` 这样可以维持当前客户端 IP 地址的哈希值；原本分发到移除服务器上请求将会自动分发到上游服务器组的下一个服务器。

  ```nginx
  upstream backend {
      ip_hash;
      server backend1.example.com;
      server backend2.example.com;
      server backend3.example.com down;
  }
  ```

- Generic hash

  通用哈希，用户可以指定字符串、变量或者两者的结合来计算哈希值。

  使用 `hash` 命令。

  ```nginx
  upstream backend {
      hash $request_uri consistent;
      server backend1.example.com;
      server backend2.example.com;
  }
  ```

  可选参数 `consistent` 能够使哈希映射保持不变，这样上游服务器增加或者减少只会导致少量的重新映射。

- Least Time(NGINX Plus only)

  最少时间，负载均衡选择平均延迟最小以及活跃连接数最少的。平均延迟通过指定 `header`、`last_byte`、`last_byte inflight` 计算得出。

  使用 `least_time` 命令。

  ```nginx
  upstream backend {
      least_time header;
      server backend1.example.com;
      server backend2.example.com;
  }
  ```

- Random

  随机，请求随机地分发到上游服务器。

  如果指定了 `two` 参数，那么

  1. NGINX 通过权值随机选择两台服务器；
  2. 通过指定的方法在两台中选择一台：
     - `least_conn`
     - `least_time=header` (NGINX Plus)
     - `least_time=last_byte` (NGINX Plus)

  使用 `random` 命令。

  ```nginx
  upstream backend {
      least_time header;
      server backend1.example.com;
      server backend2.example.com;
      server backend3.example.com;
      server backend4.example.com;
  }
  ```

  该方法适合分布式环境，例如多个负载均衡分发到同一组上游服务器；单台负载均衡适合其它方法。

  **注意：**如果要指定算法，应该将相应命令置于 `upstream` 块 `server` 命令之上。

### 权重

在轮询算法下每台上游服务器默认权重为 `1`。

```nginx
upstream backend {
    server backend1.example.com weight=5;
    server backend2.example.com;
}
```

本例中，每六个请求中五个发往第一台上游服务器，一个发往第二台服务器。

### 慢启动

慢启动能够防止服务器刚恢复就过载。

NGINX Plux 提供 *慢启动* 能够使上游服务器的权重从零慢慢提高到设定值。通过在 `server` 指令中引入 `slow_start` 参数。

```nginx
upstream backend {
    server backend1.example.com slow_start=30s;
    server backend2.example.com;
}
```

本例 `slow_start=30s` 设置服务器在三十秒内提升连接数至正常值。

如果上游服务器组只有单台，那么 `max_fails`、`fail_timeout`、`slow_start` 参数会被忽略并且该服务器被认作一直可用的。

### 持久化会话

NGINX Plus 可以使同一个用户会话分发到同一台上游服务器。

NGINX Plus 支持三种方法，使用 `sticky` 指令配置。开源版使用上方提到的 `hash` 或 `ip_hash` 命令。

- Sticky cookie

  NGINX Plux 将第一次分发请求的上游服务器标识放如会话 *cookie* 中，以后的请求都会按照 *cookie* 中的值发送到第一次分发的上游服务器。

  ```nginx
  upstream backend {
      server backend1.example.com;
      server backend2.example.com;
      sticky cookie sev_id expires=1h domain=.example.com path=/;
  }
  ```

  本例使用 `sev_id` 参数设置 *cookie* 名称。可选 `expires`  参数指定浏览器保留 *cookie* 时间；可选 `domain` 参数指定使用的域名以及可选 `path` 参数指定 *cookie* 的可用路径。

  本方法使最简单的持久化会话的方法。

- sticky route

  NGINX Plus 收到第一条请求时向客户端声明一个 "route"。随后的请求对比 `server` 命令的 `route` 参数分发到指定的上游服务器。路由信息通过 *cookie* 或者请求请求的 *URI*。

  ```nginx
  upstream backend {
      server backend1.example.com route=a;
      server backend2.example.com route=b;
      sticky route $route_cookie $route_uri;
  }
  ```

- Cookie lean

  NGINX Plux 首先通过检查请求或响应找到会话标识符。NGINX Plux ”学习“哪台上游服务器对应哪种会话标识符。通常，标识符在 *HTTP cookie* 中。当一个请求的会话标识符负载均衡”学会了“，负载均衡将其分发到相应的服务器上：

  ```nginx
  upstream backend {
      server backend1.example.com;
      server backend2.example.com;
      sticky learn
          create=$upstream_cookie_examplecookie
          lookup=$cookie_examplecookie
          zone=cline_session:1m
          timeout=1h;
  }
  ```

  本例有一台上游服务器通过设置 *cookie* `EXAMPLECOOKIE` 开启了新会话。参数解释见官方文档。

  本方法不用维持客户端的之间的 *cookie*，所有的信息都保存与共享的内存区域。

  如果负载均衡集群使用该方法，可以同步它们共享的内存区域。

### 限制连接数 

 NGINX Plus 可以通过 `max_conns` 参数设置上游服务器的最大连接数。

当到达最大连接数，请求会被放置于队列中，可以通过 `queue` 命令设置同时能置于队列中的最大请求数。

```nginx
upstream backend {
    server backend1.example.com max_conns=3;
    server backend2.example.com;
    queue 100 timeout=70;
}
```

客户端会收到错误返回如果队列满了或者无法指定上游服务器。

如果在其它 *worker processes* 中开着闲置的长连接，`max_conns`  限制会被忽略。实际服务器的连接数会超过多个 *worker processes* 共享的配置文件中设置的 `max_conns` 数。

### 心跳检测

NGINX 可以持续监测上游服务器，发现挂了的服务器以及优雅地将恢复地服务器加入负载均衡服务器组中。